# ML Model Deployment Showcase

A full-stack ML model deployment showcase using **FastAPI** for the backend and **Flutter** for the frontend. This project simulates a production-level interface for testing and visualizing deployed machine learning models, with support for logging and performance insights.

---

##  Tech Stack

**Frontend**
- Flutter (Dart)
- Material Design Components
- HTTP integration with backend
- Input forms, result dashboards, and prediction logs

**Backend**
- FastAPI (Python)
- Pydantic for schema validation
- SQLite for simple logging
- Simulated model response (can be extended to real ML model)
- REST APIs for predictions and logs

---

## ğŸ” Features

- Upload input for ML prediction via a Flutter UI
- View prediction results in real-time
- View log history of past predictions
- Full API backend with schema validation
- Ready-to-extend with actual ML model (plug-in support)
- Easily portable and modifiable

---

##  Project Structure

ml_model_showcase/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ config/
â”‚ â”‚ â””â”€â”€ .env.example
â”‚ â”œâ”€â”€ database/
â”‚ â”‚ â””â”€â”€ db.py
â”‚ â”œâ”€â”€ logs/
â”‚ â”‚ â””â”€â”€ logger.py
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â””â”€â”€ dummy_model.py
â”‚ â”œâ”€â”€ routes/
â”‚ â”‚ â””â”€â”€ predict.py
â”‚ â”œâ”€â”€ schemas/
â”‚ â”‚ â””â”€â”€ input_output.py
â”‚ â”œâ”€â”€ services/
â”‚ â”‚ â””â”€â”€ predict_service.py
â”‚ â”œâ”€â”€ main.py
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ lib/
â”‚ â”‚ â”œâ”€â”€ main.dart
â”‚ â”‚ â”œâ”€â”€ screens/
â”‚ â”‚ â””â”€â”€ widgets/
â”‚ â”œâ”€â”€ android/ ios/ web/ etc.
â”‚ â””â”€â”€ pubspec.yaml
â””â”€â”€ README.md

yaml
Copy
Edit

---

##  Getting Started

### Backend (FastAPI)

```bash
cd backend
python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate on Windows
pip install -r requirements.txt
uvicorn main:app --reload
API available at http://localhost:8000

Frontend (Flutter)
bash
Copy
Edit
cd frontend
flutter pub get
flutter run
Make sure a device/emulator is running.

 API Endpoints
Method	Endpoint	Description
POST	/predict	Submit input, get prediction
GET	/logs	View all past logs

Environment Variables
env
Copy
Edit
# backend/config/.env.example

DATABASE_URL=sqlite:///./ml_logs.db
ğŸ›  Future Enhancements
Plug in a real ML model (TensorFlow, PyTorch, etc.)

Add user authentication (JWT or Firebase)

Deploy backend on AWS / GCP

Dockerize for production

Improve UI with charts and filters

License
This project is open-source and free to use.